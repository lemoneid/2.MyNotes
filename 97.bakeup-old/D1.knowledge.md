---
id : D1.knowledge
title : D1.knowledge
typora-root-url : ../

---



[TOC]

# 计算机操作系统

## 基本特征

### 1. 并发

并发是指宏观上在一段时间内能同时运行多个程序,同一时刻只能有一条指令执行，但多个进程指令被快速轮换执行，而并行则指同一时刻能运行多个指令。

并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。

操作系统通过引入进程和线程，使得程序能够并发运行。

### 2. 共享

共享是指系统中的资源可以被多个并发进程共同使用。

有两种共享方式：互斥共享和同时共享。

互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。

### 3. 虚拟

虚拟技术把一个物理实体转换为多个逻辑实体。

主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。

多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。

虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。

### 4. 异步

异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。



### 计算密集任务和IO密集任务

* 计算密集型任务
  * 特点是要进行大量的计算，消耗CPU资源，比如计算圆周率、对视频进行高清解码等等，全靠CPU的运算能力。
  * 虽然可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数。

* IO密集型任务
  * 涉及到网络、磁盘IO的任务都是IO密集型任务，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。
  * 对于IO密集型任务，任务越多，CPU效率越高，但也有一个限度。常见的大部分任务都是IO密集型任务，比如Web应用。

### 单核CPU/多核CPU/多CPU

> * 都是一个CPU，不同的是每个CPU上的核心数。
> * 多核CPU是多个CPU的替代方案，同时也减少了功耗。
> * 一个核心只能同时执行一个线程。

* 单核CPU
  * 一个CPU中只有一个核心处理器
* 多核CPU
  * 一个CPU有多个核心处理器，处理器之间通过**CPU内部总线**进行通讯
* 多CPU
  * 简单的多个CPU工作在同一个系统上，多个CPU之间通过**主板上的总线**进行通讯

## 基本功能

### 1. 进程管理

进程控制、进程同步、进程通信、死锁处理、处理机调度等。

### 2. 内存管理

内存分配、地址映射、内存保护与共享、虚拟内存等。

### 3. 文件管理

文件存储空间的管理、目录管理、文件读写管理和保护等。

### 4. 设备管理

完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。

主要包括缓冲管理、设备分配、设备处理、虛拟设备等。

## 程序的局部性原理

### 基本概念

程序倾向于引用临近于其他最近引用过的数据项的数据项，或最近引用过的数据项本身，这种倾向性被称为局部性原理。

* 时间局部性
  * 良好时间局部性的程序中，被引用过一次的内存位置很可能在不远的将来再被多次引用
* 空间局部性
  * 良好空间局部性的程序中，一个内存位置被引用，程序很可能在不远的将来引用其附近的一个内存位置 

### 从硬件和操作系统层面看如何利用局部性

* 硬件层
  * 局部性原理允许硬件引入高速缓存存储器这种小而快速的存储器来存储最近被引用的指令和数据，从而提高对主存的访问速度
* 操作系统
  * 允许系统使用主存作为虚拟地址空间作为最近被引用块的高速缓存

### [从存储结构看如何利用局部性](https://www.jianshu.com/p/5c9b28c95c64)

存储器层次结构的中心思想是，对于每个 k，位于 k 层的更快更小的存储设备作为位于 k + 1 层的更大更慢的存储设备的缓存。

* 时间局部性
  * 同一数据对象可能被多次使用。一旦一个数据对象在第一次不命中时被复制到缓存中，我们就会期望后面对目标有一系列的访问命中。因为缓存比低一层的存储设备更快，对后面的命中的服务会比最开始的不命中的快很多。 
* 空间局部性
  * 块通常包含多个数据对象。我们会期望后面对该块中其他对象的访问能补偿不命中后复制该块的花费。 



## 用户态和内核态

### 概念

> * 用户态和内核态是操作系统的两种运行级别，两者最大的区别就是特权级不同。
> * 用户态拥有最低的特权级，内核态拥有较高的特权级。
> * 运行在用户态的程序不能直接访问操作系统内核数据结构和程序
> * 操作系统的数据都是存放于系统空间的，用户进程的数据是存放于用户空间的。
>   * 分开来存放，就让系统的数据和用户的数据互不干扰，保证系统的稳定性。
>   * 分开存放，管理上很方便，而更重要的是，将用户的数据和系统的数据隔离开，就可以对两部分的数据的访问进行控制。这样就可以确保用户程序不能随便操作系统的数据，这样防止用户程序误操作或者是恶意破坏系统。

### [用户态和内核态可以通过指针传递数据吗？](http://blog.chinaunix.net/uid-26611973-id-3190018.html)

* 用户态不能访问内核态的指针
  * 为了实现内存的保护，防止越界访问而造成受保护内存的被非法修改，甚至造成系统的崩溃，这种直接传递数据指针来传递数据的方式是被禁止的。
* 内核态可以访问用户态的指针(有前提)
  * 必须保证用户态虚拟空间的指针（虚拟空间的地址），已经分配物理地址，否则指针传入内核态中将不会引发缺页异常而报错
* [内核中访问用户进程的地址的时候用copy_from_user，而不是用memcpy直接拷贝(或者说使用用户态指针)](https://blog.csdn.net/u014089131/article/details/56272892)
  * copy_from_user主要是这个函数提供了两个功能
    * 对用户进程传过来的地址范围进行合法性检查；
    * 当用户传来的地址没有分配物理地址时，定义了缺页处理后的异常发生地址，保证程序顺利执行； 
    * 对于用户进程访问虚拟地址，如果还未分配物理地址，就会触发内核缺页异常，接着内核会负责分配物理地址，并修改映射页表。这个过程对于用户进程是完全透明的。但是在内核空间发生缺页时，必须显式处理，否则会导致内核出现错误
  * 直接使用memcpy时为什么没有出现异常
    * 只有用户传来的地址空间没有分配对应的物理地址时才会进行修复，如果用户进程之前已经使用过这段空间，代表已经分配了物理地址，自然不会发生缺页异常。 

### 两种状态转换

* 系统调用
  * 用户进程主动要求切换到内核态的一种方式，用户进程通过系统调用申请操作系统提供的服务程序完成工作 
* 异常
  * 当CPU在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前运行进程切换到处理此异常的内核相关程序中，也就到了内核态，比如缺页异常。 
* 外围设备中断
  * 当外围设备完成用户请求的操作之后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条将要执行的指令，转而去执行中断信号的处理程序 
  * 比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等 



## 系统调用

如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。

 [![img](https://camo.githubusercontent.com/e6e9338fcb2f8c849b5ed9798862d27937d80c94721948dd87c5dec1e739c2c6/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f74475056302e706e67)](https://camo.githubusercontent.com/e6e9338fcb2f8c849b5ed9798862d27937d80c94721948dd87c5dec1e739c2c6/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f74475056302e706e67) 



Linux 的系统调用主要有以下这些：

| Task     | Commands                    |
| -------- | --------------------------- |
| 进程控制 | fork(); exit(); wait();     |
| 进程通信 | pipe(); shmget(); mmap();   |
| 文件操作 | open(); read(); write();    |
| 设备操作 | ioctl(); read(); write();   |
| 信息维护 | getpid(); alarm(); sleep(); |
| 安全     | chmod(); umask(); chown();  |

## [库函数和系统调用的区别](https://www.cnblogs.com/liwei0526vip/p/8998751.html)

### 概念

* 库函数调用是语言或应用程序的一部分，而系统调用是操作系统的一部分，跨平台技术的原理就是通过库函数实现的，库函数可以理解为是对系统调用的一层封装，但库函数不是必须包含系统调用。
* 库函数有可能包含有一个系统调用，有可能有好几个系统调用，当然也有可能没有系统调用，比如有些操作不需要涉及内核的功能。

### 区别

> * 所有 C 函数库是相同的，而各个操作系统的系统调用是不同的。
> * 函数库调用是调用函数库中的一个程序，而系统调用是调用系统内核的服务。
> * 函数库调用是与用户程序相联系，而系统调用是操作系统的一个进入点
> * 函数库调用是在用户地址空间执行，而系统调用是在内核地址空间执行
> * 函数库调用的运行时间属于「用户」时间，而系统调用的运行时间属于「系统」时间
> * 函数库调用属于过程调用，开销较小，而系统调用需要切换到内核上下文环境然后切换回来，开销较大
> * 在C函数库libc中大约 300 个程序，在 UNIX 中大约有 90 个系统调用
> * 函数库典型的 C 函数：system, fprintf, malloc，而典型的系统调用：chdir, fork, write, brk

### 为什么不直接用函数调用

* 因为读写文件通常是大量的数据（相对于底层驱动的系统调用所实现的数据操作单位），这时，使用库函数可以大大减少系统调用的次数。这是因为**缓冲区技术**，在用户空间和内核空间对文件操作都使用了缓冲区。当用户空间缓冲区满或者写操作结束时，才将用户缓冲区的内容写到内核缓存区。同理，内核缓冲区满或写结束时，才将内核缓冲区内容写到文件对应的硬件媒介。
* 为了保证可移植性

### [库函数的缓冲区](https://blog.csdn.net/it_liuwei/article/details/45022671)

* 对于库函数，如果标准输出连到终端设备(直接输出到屏幕)，则它是行缓冲的（遇到回车换行符或者是缓冲区满了才输出）；否则（输出到文件）是全缓冲的（缓冲区填满或者是程序运行结束了才输出）。
* 程序运行结束时，会刷新所有的缓冲区。

由于上面的缓冲机制，也给我们编写程序时带来了一些奇怪的问题。解决办法有如下两种：

* 任何时候我们都可以使用fflush(stdout)来刷新标准输出缓冲区。
* 使用不带缓冲的系统调用write替代printf输出。

### 系统调用底层原理

* 每个系统调用函数都有一个系统调用号
* 首先找到系统调用对应的中断号（Linux下是int 0x80），然后在中断向量表中找到对应的中断处理函数，再根据系统调用号，在中断处理函数找到对应系统调用函数进行执行。

## [跨平台技术实现原理](https://segmentfault.com/q/1010000005178192)

现有跨平台技术就是通过库函数调用实现的，不使用系统函数调用。

* Qt如何识别不同系统
  *  Qt各个操作系统都有特定的宏，然后代码里面根据不同的宏调用不同平台的API



## 宏内核和微内核

### 1. 宏内核

宏内核是将操作系统功能作为一个紧密结合的整体放到内核。

由于各模块共享信息，因此有很高的性能。

### 2. 微内核

由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立。

在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。

因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f325f31345f6d6963726f6b65726e656c4172636869746563747572652e6a7067)](https://camo.githubusercontent.com/e244b7965823da98c230d7b71038b8ee11dcb2e30b5e8fb1272dcd76008a889f/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f325f31345f6d6963726f6b65726e656c4172636869746563747572652e6a7067) 

## 中断分类 

![缺页中断机构](/Image/D1.knowledge-photo/内存管理_虚拟内存_缺页中断_2.png) 

 

### 1. 外中断

由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。

### 2. 异常

由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。

### 3. 陷入

在用户程序中使用系统调用。

### 中断

+ 当中断发生时，CPU会立即进入内核态。实际上，用户态和内核态之间的切换也是依靠中断完成的
+ 当中断发生，当前运行的进程会暂停运作，并且交由操作系统内核对中断进行处理
+ 对于不同的中断，会进行不同的处理

发生了中断，就说明需要操作系统介入，开展管理工作。而操作系统的管理工作（比如进程切换，分配I/O设备等）需要特权指令，因此使用CPU要从内核态转入内核态。故而，**中断可以使得用户态转为内核态，使得操作系统获得计算机的控制权**。

用户态与内核态是通过寄存器`psw`来标志的：

+ 用户态--> 内核态：是通过而且只能通过中断的方式
+ 内核态--> 用户态：只是需要将`psw`设置为用户态





# 进程管理

## 进程与线程

### 1. 进程

- **进程是资源分配的基本单位**，实现操作系统的并发，对于一个进程，它在被执行前其实是一个可执行程序。这个程序是被放在磁盘上的，当它要被执行的时候，它先被加载到内存当中，然后再放入到寄存器中，最后再让cpu执行该程序，这个时候一个静态的程序就变成了进程
- 进程创建时会分配4G的内存，其中0-3G是用户空间，3-4G是内核空间，PCB存在于内核空间
- 进程的用户空间是不同的，内核空间也是不同的。比如每个进程的不同系统调用，是陷入自己独立的内核空间里面，所以每个进程内核的堆栈肯定是不一样的

#### 进程的组成

- PCB
- 程序段：存放要执行的代码
- 数据段：存放程序运行过程中处理的各种数据

#### 相比于程序，进程的特征

- 动态性：进程是程序的一次执行过程，是动态地产生、变化和消亡的

- 并发性：内存中有多个进程实体，各进程可并发执行

- 独立性：进程是能独立运行、独立获得资源、独立接受调度的基本单位

- 异步性：各进程按各自独立的、不可预知的速度向前推进，操作系统要提供“进程同步机制"来解决异步问题

- 结构性：每个进程都会配置一个PCB。结构上看，进程由程序段、数据段、PCB组成

  



#### PCB

- 每个进程的PCB都是存在所有进程共享的内核空间中，操作系统管理进程，也就是在内核空间中管理的，在内核空间中通过链表管理所有进程的PCB，如果有一个进程要被创建，实际上多分配了这么一个4G的虚拟内存，并在共享的内核空间中的双向链表中加入了自己的PCB。

- 进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，所谓的创建进程和撤销进程，都是指对 PCB 的操作。**创建进程，实际上是创建了进程实体中的PCB，而撤销进程就是撤销PCB，PCB是进程存在的唯一标志**。

- 内容
  * 标识相关：pid，ppid等等
  * 文件相关：进程需要记录打开的文件信息，于是需要文件描述符表
  * 内存相关：内存指针，指向进程的虚拟地址空间（用户空间）信息
  * 优先级相关：进程相对于其他进程的调度优先级
  * 上下文信息相关：CPU的所有寄存器中的值、进程的状态以及堆栈上的内容，当内核需要切换到另一个进程时，需要保存当前进程的所有状态，即保存当前进程的进程上下文，以便再次执行该进程时，能够恢复切换时的状态，继续执行。
  * 状态相关：进程当前的状态，说明该进程处于什么状态
  * 信号相关：进程的信号处理函数，以及记录当前进程是否还有待处理的信号
  * I/O相关：记录进程与各种I/O设备之间的交互
- 每个进程的内核空间中都有PCB，但真正的PCB是存储在物理内存上的，当进程创建和销毁时，会由操作系统操作PCB，每个进程只是虚拟地址空间，并不会存储实际数据，数据存储在物理内存中，只有一份。

下图显示了 4 个程序创建了 4 个进程，这 4 个进程可以并发地执行。

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f61366163326230382d333836312d346538352d626161382d3338323238376266656539662e706e67)](https://camo.githubusercontent.com/eb5ec7711cffa59515302907e8a7ed8993f797d861a708eba3a07128908006e2/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f61366163326230382d333836312d346538352d626161382d3338323238376266656539662e706e67)



### 2. 线程

线程是资源调度的独立单位。

一个进程中可以有多个线程，它们共享进程资源。

QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f33636436333065612d303137632d343838642d616431642d3733326234656665646466352e706e67)](https://camo.githubusercontent.com/403fa9a8094f89adcf827714e51e139f19d716c583792e1f33d81d9824899f5f/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f33636436333065612d303137632d343838642d616431642d3733326234656665646466352e706e67) 

### 3. 区别

1. 拥有资源

   - 进程是资源分配的基本单位，一个CPU同时刻只能执行一个进程

     * **单核CPU实现多进程，并发。** 通过操作系统的进程调度算法，单核CPU进行进程调度的时候，需要读取上下文+执行程序+保存上下文，即进程切换。
     * **多CPU实现多进程，并行。** 不同的进程运行在不同的CPU上。

   - 但是线程不拥有资源，线程可以访问隶属进程的资源。一个CPU核心同时刻只能执行一个线程

     * **单核CPU实现多线程，并发。** 不同线程为了使用CPU核心，则会进行线程切换，但是由于共享了程序执行环境，这个线程切换比进程切换开销少了很多。
     * **多核CPU实现多线程，并行。** CPU可以将不同线程分配到不同的CPU核心处理器中。

     

2. 调度
   线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。

3. 进程的调度和资源分配是操作系统负责，线程的调度和资源分配是CPU负责

4. 进程在创建、销毁时开销比较大，而线程比较小。
   由于创建或撤销进程时，系统都要为之分配或回收资源，进程创建的时候需要分配虚拟地址空间等系统资源，而销毁的的时候需要释放系统资源；线程只需要创建栈，栈指针，程序计数器，通用目的寄存器和条件码等，不需要创建独立的虚拟地址空间。

5. 进程切换开销比较打，线程比较小。进程切换需要分两步：切换页目录、刷新TLB以使用新的地址空间；切换内核栈和硬件上下文（寄存器）；而同一进程的线程间逻辑地址空间是一样的，不需要切换页目录、刷新TLB。
   在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU  环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。

6. 通信方面
   线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。

7. 一个进程崩溃，不会对其他进程产生影响；而一个线程崩溃，会让同一进程内的其他线程也宕掉。



> * 单CPU中进程只能是并发，多CPU计算机中进程可以并行。
> * 单CPU单核中线程只能并发，单CPU多核中线程可以并行。
> * 并行有上限，进程与CPU个数，线程与CPU核心个数有关，并不是所有线程和所有进程都能同时运行

### [TLB](https://www.cnblogs.com/linhaostudy/p/7771437.html)

TLB( Translation Look- aside buffer)专门用于缓存内存中的页表项,一般在MMU单元内部，页表一般存储在屋里内存中。当处理器要访问一个虚拟地址时,首先会在TLB中查询。如果TLB表项中没有相应的表项,称为TLB Miss,那么就需要访问页表来计算出相应的物理地址。如果TLB表项中有相应的表项,那么直接从TLB表项中获取物理地址,称为TLB命中。 

### [程序计数器PC和指令指针寄存器IP](http://blog.sina.com.cn/s/blog_5ede281a0100sn4w.html)

* 程序计数器PC
  * 用指令事先编好的程序连续存放在内存程序区中，靠地址+1的方法连续取指执行”。在八位机8080CPU中是采用先取指后执行的串行操作的原理，而其中执行地址+1指令寻址的部件就是程序计数器PC。那么在程序的执行过程中，PC始终是指向下一条要执行的指令。
  * 结论：PC中的地址就是需要转移、循环、调用子程序和中断子程序等操作时的断点。
* 指令指针寄存器IP
  * 在向上兼容的十六位机8086CPU中首先分为两个功能部件，即总线接口部件BIU和执行部件EU，BIU负责取指令，EU负责译码执行。并且当BIU执行指令排队栈中的六个字节装满后，（8088CPU是4个字节），EU开始从指令排队栈的出栈口，取指令进行译码执行，同时BIU并行操作向入栈口补充一条取指令命令。
  * 指令指针IP则是指向下个条要取指的指令，而不是EU要执行的指令。而断点则应该是要执行的指令内存地址，而不是IP内的下一条要取指的指令地址。
* PC是模型机中的概念，IP是实际使用的，调试时我们发现，IP实现的就是PC的功能。

### 为什么有了进程还需要线程？

* 优点
  * 进程可以使多个程序能并发执行，以提高资源的利用率和系统的吞吐量.
* 缺点
  * 进程在同一时间只能干一件事
  * 进程在执行的过程中如果阻塞，整个进程就会挂起，即使进程中有些工作不依赖于等待的资源，仍然不会执行。

因此，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时空开销，提高并发性

### 什么时候使用多进程和多线程

* 多核CPU——计算密集型任务。此时要尽量使用多线程，可以提高任务执行效率，例如加密解密，数据压缩解压缩（视频、音频、普通数据），否则只能使一个核心满载，而其他核心闲置.
* 单核CPU——计算密集型任务。此时的任务已经把CPU资源100%消耗了，就没必要也不可能使用多线程来提高计算效率了；相反，如果要做人机交互，最好还是要用多线程，避免用户没法对计算机进行操作。
* 单核CPU——IO密集型任务，使用多线程还是为了人机交互方便.
* 多核CPU——IO密集型任务，这就更不用说了，跟单核时候原因一样。



## 进程状态的切换

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f50726f6365737353746174652e706e67)](https://camo.githubusercontent.com/0398c2bace5b1b0695f5a34f6cfedf6e358db565408abc83dd161de71d3bfec8/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f50726f6365737353746174652e706e67) 

### 三种基本状态

- 就绪状态（ready）：等待被调度，已经具备运行条件，位于进程的就绪队列中，等待进程调度被分配CPU资源
- 运行状态（running）：当前占据CPU资源的进程的状态
- 阻塞状态（waiting）：等待资源，处于运行态的进程因发出某种资源请求，操作系统将其CPU资源剥夺，等待请求的事件满足，再变成就绪态，加入就绪队列。应该注意以下内容：

- 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

### 进程的创建和撤销

+ 创建态：进程正在被创建，操作系统需要为其分配资源、初始化PCB
+ 终止态：进程正在从系统中撤销，操作系统会回收进程拥有的资源、撤销PCB。

这两个状态是瞬态，没有哪个进程会长时间停留在此。

![进程转换知识点总结](file:///home/worst/Nutstore%20Files/1.MyNote/5.Operating_system/4.%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/img/%E8%BF%9B%E7%A8%8B%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93.png?lastModify=1633522759)

## 进程调度时机

> * 进程状态转换的时刻：进程终止、进程睡眠；
> * 当前进程的时间片用完时（current->counter=0）；
> * 设备驱动程序
> * 进程从中断、异常及系统调用返回到用户态时；

+ 需要进行调度时机
  + 当前处于运行态的进程**主动**放弃CPU
    + 进程正常终止
    + 异常终止
    + 进程主动请求资源而被堵塞（比如I/O响应）
  + 当前运行的进程**被动**放弃CPU
    + 分给进程的时间片用完
    + 有更紧急的事需要处理（比如中断）
    + 有更高优先级的进程进入就绪队列
+ 不能进程调度的时机  
  下面三个状态下的进程，只能等进程运行结束，系统才可以进行调度。
  + 在处理中断的过程中
  + 进程处于操作系统内核临界区中
  + 在原子操作过程中





## 进程调度算法

不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。

### 周转时间

周转时间 = 作业完成时间 - 作业提交时间。 

平均周转时间 = 各个作业周转时间之和 / 作业数



### 1. 批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

**1.1 先来先服务 first-come first-serverd（FCFS）**

> * 非抢占式的调度算法，按照请求的顺序进行调度。
> * 有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

**1.2 短作业优先 shortest job first（SJF）**

> * 非抢占式的调度算法，按估计运行时间最短的顺序进行调度。
> * 长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

**1.3 最短剩余时间优先 shortest remaining time next（SRTN）**

> * 最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 
> * 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。



### 2. 交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

**2.1 时间片轮转**

> * 将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。
> * 当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和时间片的大小有很大关系：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f38633636323939392d633136632d343831632d396634302d3166646261356263393136372e706e67)](https://camo.githubusercontent.com/a87daa8201015ff54a213d9ea95c1e49e7eec447938c441dd0247e80b18eaa05/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f38633636323939392d633136632d343831632d396634302d3166646261356263393136372e706e67) 



**2.2 优先级调度**

> * 为每个进程分配一个优先级，按优先级进行调度。
> * 为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

**2.3 多级反馈队列**

> * 一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。
> * 多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。
> * 每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

 [![img](https://camo.githubusercontent.com/c20fd7a3268ebc4ef0bce390344de2c5358392ecef2413d849c3095e21047980/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30343263663932382d336338652d343831352d616539632d6632373830323032633638662e706e67)](https://camo.githubusercontent.com/c20fd7a3268ebc4ef0bce390344de2c5358392ecef2413d849c3095e21047980/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30343263663932382d336338652d343831352d616539632d6632373830323032633638662e706e67) 

### 3. 实时系统

- 实时系统要求一个请求在一个确定时间内得到响应。
- 分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。



## 僵尸进程和孤儿进程

* 当父进程先结束，子进程此时就会变成孤儿进程，孤儿进程会自动向上被init进程收养，init进程完成对状态收集工作。而且这种过继的方式也是守护进程能够实现的因素。
* 如果子进程先结束，父进程并未调用wait或者waitpid获取进程状态信息，回收进程资源，那么子进程描述符就会一直保存在系统中，这种进程称为僵尸进程。
  * 僵尸进程是每个子进程退出时必然经历的过程
  * 僵尸进程的危害
    * 在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。但是仍然为其保留一定的信息（包括进程号the process ID，退出状态the termination status of the process，运行时间the amount of CPU time taken by the process等）。直到父进程通过wait / waitpid来取时才释放. 
    * 如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。  
  * 如何消除僵尸进程
    * kill发送SIGTERM或者SIGKILL信号消灭产生僵尸进程的进程，它产生的僵死进程就变成了孤儿进程，这些孤儿进程会被init进程接管
    * 子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。 



## 进程同步

### 1. 临界区

对临界资源进行访问的那段代码称为临界区。

为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

```
// entry section
// critical section;
// exit section
```

### 2. 同步与互斥

- 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。
- 互斥：多个进程在同一时刻只有一个进程能进入临界区。

### 3. 信号量

信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

- **down**   : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
- **up**  ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。

down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为 0 或者 1，那么就成为了   **互斥量（Mutex）**  ，0 表示临界区已经加锁，1 表示临界区解锁。

```cpp
typedef int semaphore;
semaphore mutex = 1;
void P1() {
    down(&mutex);
    // 临界区
    up(&mutex);
}

void P2() {
    down(&mutex);
    // 临界区
    up(&mutex);
}
```

<font size=3>   **使用信号量实现生产者-消费者问题**   </font> 

问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。

为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty  记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0  时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。

注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行  down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty =  0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为  0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。

```cpp
define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer() {
    while(TRUE) {
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer() {
    while(TRUE) {
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}
```

### 4. 管程

使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。

c 语言不支持管程，下面的示例代码使用了类 Pascal 语言来描述管程。示例代码的管程提供了 insert() 和 remove() 方法，客户端代码通过调用这两个方法来解决生产者-消费者问题。

```pascal
monitor ProducerConsumer
    integer i;
    condition c;

    procedure insert();
    begin
        // ...
    end;

    procedure remove();
    begin
        // ...
    end;
end monitor;
```

管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。

管程引入了   **条件变量**   以及相关的操作：**wait()** 和 **signal()** 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。

  **使用管程实现生产者-消费者问题**  

```pascal
// 管程
monitor ProducerConsumer
    condition full, empty;
    integer count := 0;
    condition c;

    procedure insert(item: integer);
    begin
        if count = N then wait(full);
        insert_item(item);
        count := count + 1;
        if count = 1 then signal(empty);
    end;

    function remove: integer;
    begin
        if count = 0 then wait(empty);
        remove = remove_item;
        count := count - 1;
        if count = N -1 then signal(full);
    end;
end monitor;

// 生产者客户端
procedure producer
begin
    while true do
    begin
        item = produce_item;
        ProducerConsumer.insert(item);
    end
end;

// 消费者客户端
procedure consumer
begin
    while true do
    begin
        item = ProducerConsumer.remove;
        consume_item(item);
    end
end;
```

## 经典同步问题

### 互斥同步问题分析

+ 关系分析：找出问题中描述的各个进程，分析他们之间的同步、互斥关系
+ 整理思路：根据各个进程的操作流程确定PV操作的顺序
+ 设置信号量。设置需要的信号量，并且根据条件确定信号量初值。（一般互斥信号量初值为1，同步信号量要看对应的系统资源是多少）

### 1. 哲学家进餐问题

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f61393037376630362d373538342d346632622d386332302d3361386534363932383832302e6a7067)](https://camo.githubusercontent.com/7f8eb6362323b56a5dd8ec061d7ea0c5b0d07a842132598bbed860a8bb941317/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f61393037376630362d373538342d346632622d386332302d3361386534363932383832302e6a7067) 



五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

下面是一种错误的解法，如果所有哲学家同时拿起左手边的筷子，那么所有哲学家都在等待其它哲学家吃完并释放自己手中的筷子，导致死锁。

```cpp
define N 5

void philosopher(int i) {
    while(TRUE) {
        think();
        take(i);       // 拿起左边的筷子
        take((i+1)%N); // 拿起右边的筷子
        eat();
        put(i);
        put((i+1)%N);
    }
}
```

为了防止死锁的发生，可以设置两个条件：

- 必须同时拿起左右两根筷子；
- 只有在两个邻居都没有进餐的情况下才允许进餐。

```cpp
define N 5
define LEFT (i + N - 1) % N // 左邻居
define RIGHT (i + 1) % N    // 右邻居
define THINKING 0
define HUNGRY   1
define EATING   2
typedef int semaphore;
int state[N];                // 跟踪每个哲学家的状态
semaphore mutex = 1;         // 临界区的互斥，临界区是 state 数组，对其修改需要互斥
semaphore s[N];              // 每个哲学家一个信号量

void philosopher(int i) {
    while(TRUE) {
        think(i);
        take_two(i);
        eat(i);
        put_two(i);
    }
}

void take_two(int i) {
    down(&mutex);
    state[i] = HUNGRY;
    check(i);
    up(&mutex);
    down(&s[i]); // 只有收到通知之后才可以开始吃，否则会一直等下去
}

void put_two(i) {
    down(&mutex);
    state[i] = THINKING;
    check(LEFT); // 尝试通知左右邻居，自己吃完了，你们可以开始吃了
    check(RIGHT);
    up(&mutex);
}

void eat(int i) {
    down(&mutex);
    state[i] = EATING;
    up(&mutex);
}

// 检查两个邻居是否都没有用餐，如果是的话，就 up(&s[i])，使得 down(&s[i]) 能够得到通知并继续执行
void check(i) {         
    if(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING) {
        state[i] = EATING;
        up(&s[i]);
    }
}
```



### 2. 读者-写者问题

允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。

```cpp
typedef int semaphore;
semaphore count_mutex = 1;
semaphore data_mutex = 1;
int count = 0;

void reader() {
    while(TRUE) {
        down(&count_mutex);
        count++;
        if(count == 1) down(&data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问
        up(&count_mutex);
        read();
        down(&count_mutex);
        count--;
        if(count == 0) up(&data_mutex);
        up(&count_mutex);
    }
}

void writer() {
    while(TRUE) {
        down(&data_mutex);
        write();
        up(&data_mutex);
    }
}
```

以下内容由 [@Bandi Yugandhar](https://github.com/yugandharbandi) 提供。

The first case may result Writer to starve. This case favous Writers  i.e no writer, once added to the queue, shall be kept waiting longer  than absolutely necessary(only when there are readers that entered the  queue before the writer).

```cpp
int readcount, writecount;                   //(initial value = 0)
semaphore rmutex, wmutex, readLock, resource; //(initial value = 1)

//READER
void reader() {
<ENTRY Section>
 down(&readLock);                 //  reader is trying to enter
 down(&rmutex);                  //   lock to increase readcount
  readcount++;                 
  if (readcount == 1)          
   down(&resource);              //if you are the first reader then lock  the resource
 up(&rmutex);                  //release  for other readers
 up(&readLock);                 //Done with trying to access the resource

<CRITICAL Section>
//reading is performed

<EXIT Section>
 down(&rmutex);                  //reserve exit section - avoids race condition with readers
 readcount--;                       //indicate you're leaving
  if (readcount == 0)          //checks if you are last reader leaving
   up(&resource);              //if last, you must release the locked resource
 up(&rmutex);                  //release exit section for other readers
}

//WRITER
void writer() {
  <ENTRY Section>
  down(&wmutex);                  //reserve entry section for writers - avoids race conditions
  writecount++;                //report yourself as a writer entering
  if (writecount == 1)         //checks if you're first writer
   down(&readLock);               //if you're first, then you must lock the readers out. Prevent them from trying to enter CS
  up(&wmutex);                  //release entry section

<CRITICAL Section>
 down(&resource);                //reserve the resource for yourself - prevents other writers from simultaneously editing the shared resource
  //writing is performed
 up(&resource);                //release file

<EXIT Section>
  down(&wmutex);                  //reserve exit section
  writecount--;                //indicate you're leaving
  if (writecount == 0)         //checks if you're the last writer
   up(&readLock);               //if you're last writer, you must unlock the readers. Allows them to try enter CS for reading
  up(&wmutex);                  //release exit section
}
```

We can observe that every reader is forced to acquire ReadLock. On  the otherhand, writers doesn’t need to lock individually. Once the first writer locks the ReadLock, it will be released only when there is no  writer left in the queue.

From the both cases we observed that either reader or writer has to  starve. Below solutionadds the constraint that no thread shall be  allowed to starve; that is, the operation of obtaining a lock on the  shared data will always terminate in a bounded amount of time.

```cpp
int readCount;                  // init to 0; number of readers currently accessing resource

// all semaphores initialised to 1
Semaphore resourceAccess;       // controls access (read/write) to the resource
Semaphore readCountAccess;      // for syncing changes to shared variable readCount
Semaphore serviceQueue;         // FAIRNESS: preserves ordering of requests (signaling must be FIFO)

void writer()
{ 
    down(&serviceQueue);           // wait in line to be servicexs
    // <ENTER>
    down(&resourceAccess);         // request exclusive access to resource
    // </ENTER>
    up(&serviceQueue);           // let next in line be serviced

    // <WRITE>
    writeResource();            // writing is performed
    // </WRITE>

    // <EXIT>
    up(&resourceAccess);         // release resource access for next reader/writer
    // </EXIT>
}

void reader()
{ 
    down(&serviceQueue);           // wait in line to be serviced
    down(&readCountAccess);        // request exclusive access to readCount
    // <ENTER>
    if (readCount == 0)         // if there are no readers already reading:
        down(&resourceAccess);     // request resource access for readers (writers blocked)
    readCount++;                // update count of active readers
    // </ENTER>
    up(&serviceQueue);           // let next in line be serviced
    up(&readCountAccess);        // release access to readCount

    // <READ>
    readResource();             // reading is performed
    // </READ>

    down(&readCountAccess);        // request exclusive access to readCount
    // <EXIT>
    readCount--;                // update count of active readers
    if (readCount == 0)         // if there are no readers left:
        up(&resourceAccess);     // release resource access for all
    // </EXIT>
    up(&readCountAccess);        // release access to readCount
}
```



## forkv fork clone

fork、v_fork、clone底层都是do_fork，追踪发现底层使用的是sys_clone

* fork
  *  父进程fork之后创建子进程，子进程复制父进程的所有资源，子进程的代码段、数据段、堆栈都是指向父进程的物理空间，但此时仅仅是子进程的虚拟地址空间和父进程指向的物理地址空间建立了映射关系，并没有真正复制
  *  由于fork()后会产生一个和父进程完全相同的子进程，但子进程在此后多会exec系统调用，处于效率考虑，linux中引入了“写时复制技术-Copy-On-Write”
  *  若两个进程一直只是读数据，则子进程一直不会复制，直到任一进程进行写操作
  *  父进程和子进程执行顺序没有规定，可以乱序执行
  *  读时共享，写时复制
* vfork
  *  vfork也是创建一个子进程，但是子进程共享父进程的空间。在vfork创建子进程之后，父进程阻塞，直到子进程执行了exec()或者exit()。
  *  规定必须子进程先执行
  *  严格意义上讲，vfork产生的不叫进程，因为他没有独立的地址空间，和父进程共享同一个

## 进程通信

进程同步与进程通信很容易混淆，它们的区别在于：

- 进程同步：控制多个进程按一定顺序执行；
- 进程通信：进程间传输信息。

进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。

### 1. 管道

管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。

```cpp
include <unistd.h>
int pipe(int fd[2]);
```

它具有以下限制：

- 只支持半双工通信（单向交替传输）；
- 只能在父子进程或者兄弟进程中使用。

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f35336364396164652d623061362d343339392d623464652d3766316662643036636466622e706e67)](https://camo.githubusercontent.com/af6ac5de61c835b0fe14c799c244632fa04239ef2ca9421eee543392353297c8/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f35336364396164652d623061362d343339392d623464652d3766316662643036636466622e706e67) 



### 2. FIFO

也称为命名管道，去除了管道只能在父子进程中使用的限制。

```cpp
include <sys/stat.h>
int mkfifo(const char *path, mode_t mode);
int mkfifoat(int fd, const char *path, mode_t mode);
```

FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32616335306238312d643932612d343430312d623965632d6632313133656363333037362e706e67)](https://camo.githubusercontent.com/8c4dd36cf4d1509b9c3ae0500085617fee811f7a83602a71e64769753b66b66b/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32616335306238312d643932612d343430312d623965632d6632313133656363333037362e706e67) 



### 3. 消息队列

相比于 FIFO，消息队列具有以下优点：

- 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
- 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
- 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

### 4. 信号量

它是一个计数器，用于为多个进程提供对共享数据对象的访问。

### 5. 共享存储

允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。

需要使用信号量用来同步对共享存储的访问。

多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

**要互斥的访问共享空间**

### 6. 套接字

与其它通信机制不同的是，它可用于不同机器间的进程通信。



### 进程之间的通信方式以及优缺点

进程间通信主要包括管道、系统IPC（包括消息队列、信号、共享内存等）、本地套接字socket。

- 管道（PIPE）

  - 有名管道：一种半双工的通信方式，它允许无亲缘关系进程间的通信
    - 优点：可以实现任意关系的进程间的通信
    - 缺点：
      1. 长期存于系统中，使用不当容易出错
      2. 缓冲区有限
  - 无名管道：一种半双工的通信方式，只能在具有亲缘关系的进程间使用（父子进程）
    - 优点：简单方便
    - 缺点：
      1. 局限于单向通信
      2. 只能创建在它的进程以及其有亲缘关系的进程之间
      3. 缓冲区有限

- 信号量（Semaphore）：一个计数器，可以用来控制多个线程对共享资源的访问

  - 优点：可以同步进程
  - 缺点：信号量有限

- 信号（Signal）：一种比较复杂的通信方式，用于通知接收进程某个事件已经发生

- 消息队列（Message Queue）：是消息的链表，存放在内核中并由消息队列标识符标识

  - 消息队列克服了信号传递信息少，管道缓冲区大小受限的缺点
  - 一个消息队列由一个标识符（即队列ID）来标记

  - 优点：可以实现任意进程间的通信，并通过系统调用函数来实现消息发送和接收之间的同步，无需考虑同步问题，方便
  - 缺点：信息的复制需要额外消耗 CPU 的时间，不适宜于信息量大或操作频繁的场合

- [共享内存](https://blog.csdn.net/hj605635529/article/details/73163513)（Shared Memory）：映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问，所以需要进行同步 ，一般与信号量配合使用。

  - shm
  - mmap 

  - 优点：无须复制，快捷，信息量大
  - 缺点：
    1. 通信是通过将共享空间缓冲区直接附加到进程的虚拟地址空间中来实现的，因此进程间的读写操作的同步问题
    2. 利用内存缓冲区直接交换信息，内存的实体存在于计算机中，只能同一个计算机系统中的诸多进程共享，不方便网络通信

- 套接字（Socket）：可用于不同计算机间的进程通信

  - 本地套接字用于本机不同进程间通信，另外普通套接字可以用于不同主机间的进程间通信。

  - 优点：
    1. 传输数据为字节级，传输数据可自定义，数据量小效率高
    2. 传输数据时间短，性能高
    3. 适合于客户端和服务器端之间信息实时交互
    4. 可以加密,数据安全性强
  - 缺点：需对传输的数据进行解析，转化成应用级的数据。



[共享内存底层原理](https://blog.csdn.net/joejames/article/details/37958017)

共享内存有两个，一个mmap，一个systemV的shmget

* 虚拟内存在硬盘上

### 不同进程如何访问共享内存？

### [进程异常退出共享内存会销毁吗](https://blog.csdn.net/brucexu1978/article/details/7728717)

## 线程之间的通信方式

- 锁机制：包括互斥锁/量（mutex）、读写锁（reader-writer lock）、自旋锁（spin lock）、条件变量（condition）
  - 互斥锁/量（mutex）：提供了以排他方式防止数据结构被并发修改的方法。
  - 读写锁（reader-writer lock）：允许多个线程同时读共享数据，而对写操作是互斥的。
  - 自旋锁（spin lock）与互斥锁类似，都是为了保护共享资源。互斥锁是当资源被占用，申请者进入睡眠状态；而自旋锁则循环检测保持者是否已经释放锁。
  - 条件变量（condition）：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
- 信号量机制(Semaphore)
  - 无名线程信号量
  - 命名线程信号量
- 信号机制(Signal)：类似进程间的信号处理
- 屏障（barrier）：屏障允许每个线程等待，直到所有的合作线程都达到某一点，然后从该点继续执行。

线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制

> 进程之间的通信方式以及优缺点来源于：[进程线程面试题总结](http://blog.csdn.net/wujiafei_njgcxy/article/details/77098977)

### 信号量

信号量是一种特殊的变量，可用于线程同步。它只取自然数值，并且只支持两种操作：

> * P(SV):如果信号量SV大于0，将它减一；如果SV值为0，则挂起该线程。
> * V(SV)：如果有其他进程因为等待SV而挂起，则唤醒，然后将SV+1；否则直接将SV+1。

* 系统调用
  * sem_wait（sem_t *sem）：以原子操作的方式将信号量减1，如果信号量值为0，则sem_wait将被阻塞，直到这个信号量具有非0值。
  * sem_post（sem_t *sem)：以原子操作将信号量值+1。当信号量大于0时，其他正在调用sem_wait等待信号量的线程将被唤醒。


### 互斥量

互斥量又称互斥锁，主要用于线程互斥，不能保证按序访问，可以和条件锁一起实现同步。当进入临界区      时，需要获得互斥锁并且加锁；当离开临界区时，需要对互斥锁解锁，以唤醒其他等待该互斥锁的线程。

* 系统调用
  * pthread_mutex_init:初始化互斥锁
  * pthread_mutex_destroy：销毁互斥锁
  * pthread_mutex_lock：以原子操作的方式给一个互斥锁加锁，如果目标互斥锁已经被上锁，pthread_mutex_lock调用将阻塞，直到该互斥锁的占有者将其解锁。
  * pthread_mutex_unlock:以一个原子操作的方式给一个互斥锁解锁。


### 条件变量

条件变量，用于在线程之间同步共享数据的值。条件变量提供一种线程间通信机制：当某个共享数据达到某个值时，唤醒等待这个共享数据的一个/多个线程。即，当某个共享变量等于某个值时，调用 signal/broadcast。此时操作共享变量时需要加锁。

* 系统调用
  * pthread_cond_init:初始化条件变量
  * pthread_cond_destroy：销毁条件变量
  * pthread_cond_signal：唤醒一个等待目标条件变量的线程。哪个线程被唤醒取决于调度策略和优先级。
  * pthread_cond_wait：等待目标条件变量。需要一个加锁的互斥锁确保操作的原子性。该函数中在进入wait状态前首先进行解锁，然后接收到信号后会再加锁，保证该线程对共享资源正确访问。 



### 进程之间私有和共享的资源

- 私有：地址空间、堆、全局变量、栈、寄存器（0-3G的用户空间）
- 共享：代码段，公共数据，进程目录，进程 ID（3-4G的内核空间）



### 线程之间私有和共享的资源

- 私有：**线程栈，寄存器，程序寄存器**，线程ID，错误返回码，信号屏蔽字，调度优先级
- 共享：文件描述符表，堆，地址空间，全局变量，静态变量，进程代码段，进程的当前目录和进程用户ID与进程组ID



### 多进程与多线程间的对比、优劣与选择

##### 对比

| 对比维度       | 多进程                                                       | 多线程                                                       | 总结     |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | -------- |
| 数据共享、同步 | 数据共享复杂，需要用 IPC；数据是分开的，同步简单             | 因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂 | 各有优势 |
| 内存、CPU      | 占用内存多，切换复杂，CPU 利用率低                           | 占用内存少，切换简单，CPU 利用率高                           | 线程占优 |
| 创建销毁、切换 | 创建销毁、切换复杂，速度慢                                   | 创建销毁、切换简单，速度很快                                 | 线程占优 |
| 编程、调试     | 编程简单，调试简单                                           | 编程复杂，调试复杂                                           | 进程占优 |
| 可靠性         | 进程间不会互相影响                                           | 一个线程挂掉将导致整个进程挂掉                               | 进程占优 |
| 分布式         | 适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单 | 适应于多核分布式                                             | 进程占优 |



##### 优劣

| 优劣 | 多进程                                   | 多线程                                   |
| ---- | ---------------------------------------- | ---------------------------------------- |
| 优点 | 编程、调试简单，可靠性较高               | 创建、销毁、切换速度快，内存、资源占用小 |
| 缺点 | 创建、销毁、切换速度慢，内存、资源占用大 | 编程、调试复杂，可靠性较差               |



##### 选择

- 需要频繁创建销毁的优先用线程
- 需要进行大量计算的优先使用线程
- 强相关的处理用线程，弱相关的处理用进程
- 可能要扩展到多机分布的用进程，多核分布的用线程
- 都满足需求的情况下，用你最熟悉、最拿手的方式

## [协程](https://blog.csdn.net/pinganting/article/details/53750142)

[协程学习笔记](https://blog.csdn.net/somezz/article/details/81265198)

### 协程概述

* 协程是轻量级线程，拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈。
* 协程能保留上一次调用时的状态，即所有局部状态的一个特定组合，每次过程重入时，就相当于进入上一次调用的状态。

### 协程和线程的区别

* 协程最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。
* 不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。 

### 应用场景

* I/O 密集型任务。

> * 这一点与多线程有些类似，但协程调用是在一个线程内进行的，是单线程，切换的开销小，因此效率上略高于多线程。
> * 当程序在执行 I/O 时操作时，CPU 是空闲的，此时可以充分利用 CPU 的时间片来处理其他任务。在单线程中，一个函数调用，一般是从函数的第一行代码开始执行，结束于 return 语句、异常或者函数执行（也可以认为是隐式地返回了 None ）。 
> * 有了协程，我们在函数的执行过程中，如果遇到了耗时的 I/O 操作，函数可以临时让出控制权，让 CPU 执行其他函数，等 I/O 操作执行完毕以后再收回控制权。



## Linux 内核的同步方式

### 原因

在现代操作系统里，同一时间可能有多个内核执行流在执行，因此内核其实像多进程多线程编程一样也需要一些同步机制来同步各执行单元对共享数据的访问。尤其是在多处理器系统上，更需要一些同步机制来同步不同处理器上的执行单元对共享的数据的访问。

### 同步方式

- 原子操作
- 信号量（semaphore）
- 读写信号量（rw_semaphore）
- 自旋锁（spinlock）
- 大内核锁（BKL，Big Kernel Lock）
- 读写锁（rwlock）
- 大读者锁（brlock-Big Reader Lock）
- 读-拷贝修改(RCU，Read-Copy Update)
- 顺序锁（seqlock）

> 来自：[Linux 内核的同步机制，第 1 部分](https://www.ibm.com/developerworks/cn/linux/l-synch/part1/)、[Linux 内核的同步机制，第 2 部分](https://www.ibm.com/developerworks/cn/linux/l-synch/part2/)

## LINUX系统中的锁

互斥锁，读写锁，自旋锁

> * 互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。**当获取锁操作失败时，线程会进入睡眠**，等待锁释放时被唤醒

> * 读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它**获取写锁失败的线程都会进入睡眠状态**，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。

> * 自旋锁：spinlock，在任何时刻同样只能有一个线程访问对象。但是**当获取锁操作失败时，不会进入睡眠，而是会在原地自旋**，循环检测锁的保持者是否释放，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。 



## [信号处理机制](http://www.360doc.com/content/16/0804/10/30953065_580685165.shtml)


## [哪两个信号不能忽略](https://www.cnblogs.com/Lynn-Zhang/p/5677118.html)

SIGKILL和SIGSTOP，这两种信号不能被忽略

* 它们向超级用户提供一种使进程终止或停止的可靠方法。
* 如果忽略某些由硬件异常产生的信号（例如非法存储访问或除以0），则进程的行为是示定义的。

## [原子操作和锁机制](https://blog.csdn.net/CringKong/article/details/79966161)

[原子操作实现同步](



# 死锁

## 必要条件

多个并发进程因争夺系统资源而产生相互等待的现象。

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f63303337633930312d376561652d346533312d613165342d3964343133323965356333652e706e67)](https://camo.githubusercontent.com/8940a52ebe48a8a0162bd751bed592a6825f0a6ae9c52a369f511d4e29a4a4c2/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f63303337633930312d376561652d346533312d613165342d3964343133323965356333652e706e67) 



- 互斥条件：每个资源要么已经分配给了一个进程，要么就是可用的。
  进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源；
  
- 占有和等待（请求和保持条件）：已经得到了某个资源的进程可以再请求新的资源。
  进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源
  
- 不可抢占（不可剥夺条件）：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。

- 环路等待条件：进程发生死锁后，必然存在一个进程-资源之间的环形链 ，有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。


## 原因

- 系统资源不足

- 资源分配不当

- 进程运行推进顺序不合适

## 处理方法

主要有以下四种方法：

- 鸵鸟策略
- 死锁检测与死锁恢复
- 死锁预防
- 死锁避免

## 鸵鸟策略

把头埋在沙子里，假装根本没发生问题。

因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。

当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。



## 死锁检测与死锁恢复

不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。

### 1. 每种类型一个资源的死锁检测

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f62316661303435332d613462302d346561652d613335322d3438616363613866666637342e706e67)](https://camo.githubusercontent.com/5663be4d3b58da1b738412ca4854b61d255974230c1c88875f96511618a5bae0/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f62316661303435332d613462302d346561652d613335322d3438616363613866666637342e706e67) 



上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。

图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。

每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。

### 2. 每种类型多个资源的死锁检测

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65316564613364352d356563382d343730382d386532352d3161303463356531316634382e706e67)](https://camo.githubusercontent.com/65aa9be0a5faea5fb50ec17101ce3e900688ad9079ac67fed8bb7fb40c8578f1/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65316564613364352d356563382d343730382d386532352d3161303463356531316634382e706e67) 



上图中，有三个进程四个资源，每个数据代表的含义如下：

- E 向量：资源总量
- A 向量：资源剩余量
- C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量
- R 矩阵：每个进程请求的资源数量

进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 A = (2 2 2 0)。P2 可以执行，执行后释放 P2 拥有的资源，A = (4 2 2 1) 。P1 也可以执行。所有进程都可以顺利执行，没有死锁。

算法总结如下：

每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。

1. 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。
2. 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。
3. 如果没有这样一个进程，算法终止。



### 3. 死锁恢复

- 利用抢占恢复
- 利用回滚恢复
- 通过杀死进程恢复

## 死锁预防

在程序运行之前预防发生死锁。

### 1. 破坏互斥条件

例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

改造独占性资源为虚拟资源，大部分资源已无法改造。

### 2. 破坏占有和等待条件

一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。

采用资源预先分配策略，即进程运行前申请全部资源，满足则运行，不然就等待，这样就不会占有且申请。

### 3. 破坏不可抢占条件

当一进程占有一独占性资源后又申请一独占性资源而无法满足，则退出原占有的资源。

### 4. 破坏环路等待

实现资源有序分配策略，给资源统一编号，进程只能按编号递增顺序来请求资源。

## 死锁避免

在程序运行时避免发生死锁。

### 1. 安全状态

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65643532333035312d363038662d346333662d623334332d3338336532643139343437302e706e67)](https://camo.githubusercontent.com/09589c4bfe0e5514a44fc74cd63069f018b03246880e1f89b887313bbbdf2073/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65643532333035312d363038662d346333662d623334332d3338336532643139343437302e706e67) 



图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数。从图 a  开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和  A，使得所有进程都能成功运行，因此可以称图 a 所示的状态时安全的。

定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。

安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法与死锁检测算法非常类似，可以结合着做参考对比。

### 2. 单个资源的银行家算法

一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f64313630656332652d636665322d343634302d626461372d3632663533653538623863302e706e67)](https://camo.githubusercontent.com/381663ffc7a4db80478e5f454a11400debf6c13628632e3396fdaa7a6e555716/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f64313630656332652d636665322d343634302d626461372d3632663533653538623863302e706e67) 



上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。

### 3. 多个资源的银行家算法

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f36326530646434662d343463332d343365652d626236652d6665646239653036383531392e706e67)](https://camo.githubusercontent.com/5334ac030b7446b89615c4319275fe27330481ac6f1a9280fc682f6dffcf5241/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f36326530646434662d343463332d343365652d626236652d6665646239653036383531392e706e67) 



上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A  分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。

检查一个状态是否安全的算法如下：

- 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。
- 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。
- 重复以上两步，直到所有进程都标记为终止，则状态时安全的。

如果一个状态不是安全的，需要拒绝进入这个状态。



## 死锁检测和死锁恢复

* 死锁检测
  * 每种类型一个资源的死锁检测
  * 每种类型多个资源的死锁检测
* 死锁恢复
  * **抢占恢复。** 从一个或多个进程中抢占足够数量的资源分配给死锁进程，以解除死锁状态
  * **回滚恢复。** 周期性地检查进程的状态（包括请求的资源），将其写入一个文件，当发生死锁，回滚到之前的某个时间点
  * **杀死进程恢复。** 终止或撤销系统中的一个或多个死锁进程，直至打破死锁状态。



# 内存管理

## 存储器层次结构

### 层次结构

本地磁盘 -> 主存(DRAM) -> L3高速缓存(SRAM) -> L2高速缓存(SRAM) -> L1高速缓存(SRAM) -> L0寄存器

### 缓存思想

> * 位于K层的更快更小的存储设备作为位于K+1层更大更慢的存储设备的缓存
> * K+1层的存储器被划分成连续的数据对象组块，称为块，数据总是以块大小为传送单元在K和K+1层之间来回复制

### 缓存命中

> * 当程序需要K+1层的某个数据对象d时，首先在当前存储在K层的块中查找d，若d刚好缓存在k层中，则称为缓存命中
> * 若缓存不命中，则需要将K+1层中包含对象d的块缓存到K层中，若K层中满了，则需要替换现存的一个块



## 虚拟内存

通过局部性原理：

+ 在程序装入的过程中，可以将程序很快用到的部分装入内存，暂时用不到的部分驻留在外村，就可以让程序开始执行，
+ 在程序执行中，当所访问信息不在内存中时，由操作系统负责将所需信息从外村调入内存，然后继续执行程序。
+ 当内存空间不够，操作系统负责将内存中暂时用不到的信息换出到外村

因此，使得操作系统可以使用一个比实际物理内存大得多内存，即虚拟内存。这个虚拟内存就解决了“页表”中的问题2，两级页表 + 虚拟内存实现，可以高效查询。



虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存，防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏，采用了虚拟内存。

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但**不需要映射到连续的物理内存**，也**不需要所有页都必须在物理内存中**。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

从上面的描述中可以看出，虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。

例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K  大小的程序。

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f37623238316231652d303539352d343032622d616533352d3863393130383463333363312e706e67)](https://camo.githubusercontent.com/01251b0ef66ccf744889c26424634aae680922be7d993522b4d831dca3c9511c/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f37623238316231652d303539352d343032622d616533352d3863393130383463333363312e706e67) 

### [虚拟内存的好处](https://www.jianshu.com/p/baf3a13c47db)

* 可以更加高效的使用物理内存
  * 虚拟地址空间一开始并没有真正的对应物理地址，而是在真正使用的时候才去对应。
  * 通过虚拟内存置换算法在访问后边的地址空间的时候就可以将前边当前没有在访问的物理页释放掉，或者交换到硬盘中。这样这个物理页又可以去对应新的虚拟地址。从而使物理内存可以充分的利用。 
* 内存管理
  *  为每个进程提供了一致的地址空间，简化内存管理
* 内存保护
  * 在使用虚拟地址的时候，暴露给程序员永远都是虚拟地址，而具体的物理地址在哪里，这个只有系统才了解。这样就提高了系统的封装性。
  * 保护了每个进程的地址空间不被其他进程破坏

#### 虚拟内存三个主要特征：

总结，针对传统的存储技术，虚拟存储有三个主要特征：

+ 多次性：无需在作业运行时一次性全部装入内存，而是运行被分成多次调入内存
+ 对换性：在无作业运行时无需一直常驻内存，而是允许在作业运行过程中将作业换入换出。
+ 虚拟性：从逻辑上扩充了内存的容量，用户看到的容量，远大于实际的容量。这是虚拟内存的体现

虚拟内存的最大容量是由于计算机地址结构（CPU寻址范围确定的），虚拟内存的实际容量 = MIN(内存和外存容量之和，CPU寻址范围)。

#### 虚拟内存的实现

虚拟内存技术，允许一个作业多次调入内存。如果采用连续分配方式，会不方便实现，因此虚拟内存的实现是建立在离散分配的内存管理方式基础上。

+ 请求分页存储管理
+ 请求分段存储管理
+ 请求段页式管理

### 请求分页存储管理 

对于的基本分页的驻留行和一次性缺点，请求分页存储管理的主要区别：

+ 在程序执行的过程中，当所访问的信息不在内存中时，由操作系统负责将所需信息从外存调入内存，然后执行程序。这是由操作系统提供的请求调页功能，将缺失页面从外存调入内存。
+ 如果内存空间不够，由操作系统将内存中暂时用不到的信息换出到外存。操作系统提供直面置换的功能，将暂时用不到的页面换出到外村。

## 虚拟内存页表寻址

### 分页

虚拟内存分割成虚拟页，物理内存被分割成物理页，用来作为磁盘和主存的传输单元。
虚拟页分为三个不相交的子集

> * 未分配的，不占磁盘空间
> * 缓存的，当前已缓存在物理内存中的已分配页，在页表中标志位为1
> * 未缓存的，未缓存在物理内存中的已分配页，在页表中标志位为0

### 页表

内存管理单元（MMU，属于硬件）管理着地址空间和物理内存的转换，操作系统为每一个进程维护了一个从虚拟地址到物理地址的映射关系的数据结构，叫页表，存储着程序地址空间到物理内存空间的映射表。

页表存放在物理内存中，物理页存放在物理内存中，虚拟页存放在磁盘上

### 页表寻址

> * 一个虚拟地址分为两部分，一部分存储页面号，一部分存储偏移量
> * 页表分为序号、页基地址、标志位
> * 访问虚拟地址，先通过页表查询页面号，查看标志位确认虚拟地址是否在物理内存中有缓存，然后由逻辑地址的高位部分先找到逻辑地址对应的页基地址，再由页基地址偏移虚拟地址中的偏移量就得到最后的物理地址
> * 一般情况下，这个过程都可以由硬件完成，所以效率还是比较高的。页式内存管理的优点就是比较灵活，内存管理以较小的页为单位，方便内存换入换出和扩充地址空间。 

## 缺页中断

在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存时(缓存不命中)，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。

缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：

> * 保护CPU现场
> * 分析中断原因
> * 转入缺页中断处理程序进行处理
> * 恢复CPU现场，继续执行

但是缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，与一般的中断存在区别：

> * 在指令执行期间产生和处理缺页中断信号
> * 一条指令在执行期间，可能产生多次缺页中断
> * 缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令。 

## 分页系统地址映射

内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。

一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。

下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），页表项最后一位表示是否存在于内存中，1 表示存在。后 12  位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f63663433383661312d353863392d346563612d613137662d6531326231653937373065622e706e67)](https://camo.githubusercontent.com/1f3a60c6aaac33dd000b9d6a39069d3ddaf2bb04c22b8bcda782eca707eb64fe/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f63663433383661312d353863392d346563612d613137662d6531326231653937373065622e706e67) 

## 页面置换算法

在程序运行过程中，如果要访问的页面不在内存中，就发生**缺页中断**从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。而用来选择淘汰哪一页的规则叫做页面置换算法。

页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。

页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

#### 分类

- 全局置换：在整个内存空间置换
- 局部置换：在本进程中进行置换

#### 算法

全局：

- 工作集算法
- 缺页率置换算法

局部：

- 最佳置换算法（OPT）
- 先进先出置换算法（FIFO）
- 最近最久未使用（LRU）算法
- 时钟（Clock）置换算法

### 1. 最佳

> OPT, Optimal replacement algorithm

所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。

是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列：

```
7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1
```

开始运行时，先将 7, 0, 1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。

### 2. 最近最久未使用

> LRU, Least Recently Used
>
> 置换最近一段时间以来最长时间未访问过的页面。根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近不会被访问。

虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。

为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

```
4，7，0，7，1，0，1，2，1，2，6
```

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65623835393232382d633066322d346263652d393130642d6439663736393239333532622e706e67)](https://camo.githubusercontent.com/c5cd2c10ae1c8526540a7af00c5390d1a953f147c4c147358953c9e929897cc3/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65623835393232382d633066322d346263652d393130642d6439663736393239333532622e706e67) 


### 3. 最近未使用

> NRU, Not Recently Used

每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类：

- R=0，M=0
- R=0，M=1
- R=1，M=0
- R=1，M=1

当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。

NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。

### 4. 先进先出

> FIFO, First In First Out
>
> 置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。

选择换出的页面是最先进入的页面。

该算法会将那些经常被访问的页面换出，导致缺页率升高。



### 5. 第二次机会算法

FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：

当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是  0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清  0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65636638616435642d353430332d343862392d623665372d6632653230666665386663612e706e67)](https://camo.githubusercontent.com/579e409ef1551a1dc1c59487bc2fd54e93129ec97573721a3027376aa7f17595/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65636638616435642d353430332d343862392d623665372d6632653230666665386663612e706e67) 





### 6. 时钟

> Clock

第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f35663565663062362d393865612d343937632d613030372d6636633535323838656162312e706e67)](https://camo.githubusercontent.com/66bf1e33e909443e7fd77bf1d37c6144162b0545ac0aa6b078928e40a4d64878/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f35663565663062362d393865612d343937632d613030372d6636633535323838656162312e706e67) 



## 分段

虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。

下图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32326465303533382d376336652d343336352d626433622d3863653363353930303231362e706e67)](https://camo.githubusercontent.com/bc968c738c37aa7ad6d63d9b95a4803f11fe14aac87f571558024d19af30d399/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32326465303533382d376336652d343336352d626433622d3863653363353930303231362e706e67) 



分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。

 [![img](https://camo.githubusercontent.com/836f0a92a1f8ff0dee7112c8fc213daa419a42e82cd543d6fd87100fc2624bec/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65303930306262322d323230612d343362372d396161392d3164356364353566663536652e706e67)](https://camo.githubusercontent.com/836f0a92a1f8ff0dee7112c8fc213daa419a42e82cd543d6fd87100fc2624bec/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65303930306262322d323230612d343362372d396161392d3164356364353566663536652e706e67) 



## 段页式

程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。

## 分页与分段的比较

- 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。
- 地址空间的维度：分页是一维地址空间，分段是二维的。
- 大小是否可以改变：页的大小不可变，段的大小可以动态改变。
- 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

# 设备管理

## 磁盘结构

- 盘面（Platter）：一个磁盘有多个盘面；
- 磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道；
- 扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小；
- 磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写）；
- 制动手臂（Actuator arm）：用于在磁道之间移动磁头；
- 主轴（Spindle）：使整个盘面转动。

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30313466626334642d643837332d346131322d623136302d3836376464616564393830372e6a7067)](https://camo.githubusercontent.com/062b5e89146b6df61a790e3585635f2d8892ab9f8f6181da26aa58a9cbd55922/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30313466626334642d643837332d346131322d623136302d3836376464616564393830372e6a7067) 

## 磁盘调度算法

读写一个磁盘块的时间的影响因素有：

- 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上）
- 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上）
- 实际的数据传输时间

其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。

### 1. 先来先服务

> FCFS, First Come First Served

按照磁盘请求的顺序进行调度。

优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。

### 2. 最短寻道时间优先

> SSTF, Shortest Seek Time First

优先调度与当前磁头所在磁道距离最近的磁道。

虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34653234383565342d333462642d343936372d396630322d3063303933623739376161612e706e67)](https://camo.githubusercontent.com/4aaee136900eb1ece1352fa6ca5b92f37e59801a6fcd0a2345afa73ca44fd5b0/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34653234383565342d333462642d343936372d396630322d3063303933623739376161612e706e67)

### 3. 电梯算法

> SCAN

电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。

电梯算法（扫描算法）和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。

因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题。

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32373163653038662d633132342d343735662d623439302d6265343466656463366432652e706e67)](https://camo.githubusercontent.com/e4956eee145c33a868e367fe6a32eb40465503a4e6a31755ca4fe5a4a83d4019/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32373163653038662d633132342d343735662d623439302d6265343466656463366432652e706e67) 

# 链接

### 装入的三种方式 

#### 绝对装入

在编译时，如果知道程序将放在内存的哪个位置，编译程序将产生绝对地址的目标代码，装入程序将按照转入模块中的地址，将程序和数据装入内存。

这个方式只是适用于单道程序的环境，程序中使用的绝对地址，可以在编译或者汇编时给出，也可由程序员直接赋予。最后装入模块直接使用的就是这个绝对地址在内存中操作。

#### 静态重定位 

![静态重定位](/Image/D1.knowledge-photo/内存管理_基础知识_静态装入.png) 

指令中的地址、数据存放，都是相对起始地址而言的逻辑地址，转入时重定位为装入的物理起实地址 + 逻辑地址。所有的地址变换都是在装入时一次性完成。

#### 动态重定位

动态装入，即动态运行时装入。编译、链接后装入模块的地址都是从0开始的。装入程序把装入模块装入内存后，并不会立即把逻辑地址转换为物理地址，而是把转换工作推迟到程序真正运行的时候才执行。因此装入内存后，依旧所有的地址依旧是逻辑地址。这个方式需要一个重定位寄存器。 

![动态装入](/Image/D1.knowledge-photo/内存管理_基础知识_动态装入.png) 

这个方式便于实现内存的不连续不分配

#### 接

![链接](/Image/D1.knowledge-photo/内存管理_基础知识_链接三种方式.png) 

可以采用重定位寄存器（又叫做基址寄存器）和界地址寄存器（又名限长寄存器）进行越界检测。重定位寄存器中存放的是进程的起实物理地址，界地址寄存器存放的是进程的最大逻辑地址寄存器



## 编译系统

以下是一个 hello.c 程序：

```cpp
include <stdio.h>int main(){    printf("hello, world\n");    return 0;}
```

在 Unix 系统上，由编译器把源文件转换为目标文件。

```shell
gcc -o hello hello.c
```

这个过程大致如下：

 [![img](https://camo.githubusercontent.com/b106110f7870e9d6faef1e5831e1ed97b94076cfbb9929cd006606f9adeb41ce/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f62333936643732362d623735662d346133322d383961322d3033613762366531396636662e6a7067)](https://camo.githubusercontent.com/b106110f7870e9d6faef1e5831e1ed97b94076cfbb9929cd006606f9adeb41ce/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f62333936643732362d623735662d346133322d383961322d3033613762366531396636662e6a7067) 



- 预处理阶段：处理以  开头的预处理命令；
- 编译阶段：翻译成汇编文件；
- 汇编阶段：将汇编文件翻译成可重定位目标文件；
- 链接阶段：将可重定位目标文件和 printf.o 等单独预编译好的目标文件进行合并，得到最终的可执行目标文件。

## 静态链接

静态链接器以一组可重定位目标文件为输入，生成一个完全链接的可执行目标文件作为输出。链接器主要完成以下两个任务：

- 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。
- 重定位：链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置。

 [![img](https://camo.githubusercontent.com/b5a16d3176db7f213f470c2d877c08b75e8fcc43ef1cc6f930b340320f2c8e9a/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34376439383538332d386262302d343563632d383132642d3437656566613061346134302e6a7067)](https://camo.githubusercontent.com/b5a16d3176db7f213f470c2d877c08b75e8fcc43ef1cc6f930b340320f2c8e9a/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34376439383538332d386262302d343563632d383132642d3437656566613061346134302e6a7067) 

## 目标文件

- 可执行目标文件：可以直接在内存中执行；
- 可重定位目标文件：可与其它可重定位目标文件在链接阶段合并，创建一个可执行目标文件；
- 共享目标文件：这是一种特殊的可重定位目标文件，可以在运行时被动态加载进内存并链接；

## 动态链接

静态库有以下两个问题：

- 当静态库更新时那么整个程序都要重新进行链接；
- 对于 printf 这种标准函数库，如果每个程序都要有代码，这会极大浪费资源。

共享库是为了解决静态库的这两个问题而设计的，在 Linux 系统中通常用 .so 后缀来表示，Windows 系统上它们被称为 DLL。它具有以下特点：

- 在给定的文件系统中一个库只有一个文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中；
- 在内存中，一个共享库的 .text 节（已编译程序的机器代码）的一个副本可以被不同的正在运行的进程共享。

 [![img](/Image/D1.knowledge-photo/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f37366463373736392d316161632d343838382d396265612d3036346631636161386537372e6a7067)](https://camo.githubusercontent.com/e4bd3c0074bc832f7b8f4d7dda678b26a51185668d5afc2f14af14198051d1eb/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f37366463373736392d316161632d343838382d396265612d3036346631636161386537372e6a7067) 



